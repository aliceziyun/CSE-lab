//
// A simple sequential MapReduce for WordCount
//

#include <string>
#include <sstream>
#include <fstream>
#include <iostream>
#include <vector>
#include <algorithm>
#include <string.h>

using namespace std;

typedef struct
{
    string key;
    string val;
} KeyVal;

bool isIndex2End(char s)
{
    if (s == ' ' || s == '\0')
        return false;
    if ((s >= 'a' && s <= 'z') || (s <= 'Z' && s >= 'A'))
        return true;
    return false;
}

//
// The map function is called once for each file of input. The first
// argument is the name of the input file, and the second is the
// file's complete contents. You should ignore the input file name,
// and look only at the contents argument. The return value is a slice
// of key/value pairs.
//
vector<KeyVal> Map(const string &filename, const string &content)
{
    // Your code goes here
    // Hints: split contents into an array of words.
    // 相当于做一个tokenize，也不用做统计全塞向量里就可以了（看输出不需要大小写转换）

    // 返回向量
    vector<KeyVal> ret;

    // 扫描content
    int index1 = 0, index2 = 0;
    while (content[index1] != '\0')
    {
        while (isIndex2End(content[index2]))
        {
            index2++;
        }
        string key = content.substr(index1, index2 - index1);
        if (key != "")
        {
            string val = "1";
            // cout << "key：" << key << endl;
            KeyVal kv;
            kv.key = key;
            kv.val = val;
            ret.push_back(kv);
        }
        index1 = index2;
        if (content[index1] == '\0')
            break;
        index1++;
        index2++;
    }
    return ret;
}

//
// The reduce function is called once for each key generated by the
// map tasks, with a list of all the values created for that key by
// any map task.
//
string Reduce(const string &key, const vector<string> &values)
{
    // Your code goes here
    // Hints: return the number of occurrences of the word.
    // 这里理论上，key是一个特殊的单词，values是一堆1
    // cout << "reduce key" << key << endl;
    string ret = "0";

    int size = values.size();
    for (int i = 0; i < size; i++)
    {
        ret = to_string(stol(ret) + stol(values[i]));
    }
    return ret;
}

int main(int argc, char **argv)
{
    if (argc < 2)
    {
        cout << "Usage: mrsequential inputfiles...\n";
        exit(1);
    }

    vector<string> filename;
    vector<KeyVal> intermediate;

    //
    // read each input file,
    // pass it to Map,
    // accumulate the intermediate Map output.
    //

    for (int i = 1; i < argc; ++i)
    {

        string filename = argv[i];
        string content;

        // Read the whole file into the buffer.
        getline(ifstream(filename), content, '\0');

        // 做map
        vector<KeyVal> KVA = Map(filename, content);

        // 把map的结果放到intermediate中
        intermediate.insert(intermediate.end(), KVA.begin(), KVA.end());
    }

    //
    // a big difference from real MapReduce is that all the
    // intermediate data is in one place, intermediate[],
    // rather than being partitioned into NxM buckets.
    //
    // sort intermediate的结果
    sort(intermediate.begin(), intermediate.end(),
         [](KeyVal const &a, KeyVal const &b)
         {
             return a.key < b.key;
         });

    //
    // call Reduce on each distinct key in intermediate[],
    // and print the result to mr-out-0.
    //
    // 对intermediate中每一个特别的key，做reduce，并输出结果
    for (unsigned int i = 0; i < intermediate.size();)
    {
        unsigned int j = i + 1;
        for (; j < intermediate.size() && intermediate[j].key == intermediate[i].key;)
            j++;

        vector<string> values;
        for (unsigned int k = i; k < j; k++)
        {
            values.push_back(intermediate[k].val);
        }

        string output = Reduce(intermediate[i].key, values);
        printf("%s %s\n", intermediate[i].key.data(), output.data());

        i = j;
    }
    return 0;
}
